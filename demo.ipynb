{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hikaru-si/.pyenv/versions/3.10.2/envs/exp_006/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import json\n",
    "import pickle\n",
    "from PIL import Image, ImageDraw\n",
    "import torch\n",
    "from paddleocr import PaddleOCR\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "from donut_layoutLMv3_3 import DonutConfig, DonutModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_list = [\n",
    "  \"--input_dir\", \"example\",\n",
    "  \"--output_dir\", \"predicts\",\n",
    "  \"--model_path\", \"model/swin-en_pubtabnet_200-400\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(input_dir='example', output_dir='predicts', model_path='model/swin-en_pubtabnet_200-400')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "#data\n",
    "parser.add_argument(\"--input_dir\", type=str, required=True)\n",
    "parser.add_argument(\"--output_dir\", type=str, required=True)\n",
    "parser.add_argument(\"--model_path\", type=str, required=True)\n",
    "args = parser.parse_args(args_list)\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.model_path.split(\"/\")[-1].startswith(\"swin-en\"):\n",
    "    from donut_swin import DonutConfig, DonutModel\n",
    "    preprocessing_data = preprocessing_data_swin\n",
    "else:\n",
    "    from donut_layoutLMv3_3 import DonutConfig, DonutModel\n",
    "    preprocessing_data = preprocessing_data_layoutlm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(args.output_dir, exist_ok=True)\n",
    "os.makedirs(args.output_dir + \"/ocr_results\", exist_ok=True)\n",
    "os.makedirs(args.output_dir + \"/model_predictions\", exist_ok=True)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    encoder_inputs= {}\n",
    "    for key in [\"input_ids\", \"bbox\", \"attention_mask\", \"pixel_values\"]:\n",
    "        encoder_inputs[key] = torch.cat([b[\"encoding_inputs\"][key] for b in batch])\n",
    "    \n",
    "    image_paths = [b[\"image_path\"] for b in batch]\n",
    "    \n",
    "    return encoder_inputs, image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/11/16 15:07:46] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=True, use_xpu=False, use_npu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/home/hikaru-si/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/home/hikaru-si/.paddleocr/whl/rec/en/en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/home/hikaru-si/.pyenv/versions/3.10.2/envs/exp_006/lib/python3.10/site-packages/paddleocr/ppocr/utils/en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=False, cls_model_dir='/home/hikaru-si/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, ocr=True, recovery=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n"
     ]
    }
   ],
   "source": [
    "ocr = PaddleOCR(use_angle_cls=False, lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_bbox(img, boxes, texts):\n",
    "    w, h = img.size\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for bb, t in zip(boxes, texts):\n",
    "        x0, y0, x1, y1 = bb\n",
    "        x0 = x0 * w\n",
    "        y0 = y0 * h\n",
    "        x1 = x1 * w\n",
    "        y1 = y1 * h\n",
    "        draw.rectangle([x0, y0, x1, y1], fill=None, outline=(225, 0, 100))\n",
    "        draw.text((x0, y0), t, fill=(225, 0, 225))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model_path):\n",
    "    with open(f\"{model_path}/model_config.json\", \"r\") as f:\n",
    "        config = json.load(f)\n",
    "    donut_config = DonutConfig.from_dict(config)\n",
    "    model = DonutModel(donut_config)\n",
    "    trained_state_dict = torch.load(f\"{model_path}/best_model.cpt\")\n",
    "    model.load_state_dict(trained_state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/11/16 15:07:52] ppocr DEBUG: dt_boxes num : 153, elapsed : 0.0766901969909668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/11/16 15:07:53] ppocr DEBUG: rec_res num  : 153, elapsed : 0.2129216194152832\n",
      "[2023/11/16 15:07:53] ppocr DEBUG: dt_boxes num : 16, elapsed : 0.015017032623291016\n",
      "[2023/11/16 15:07:53] ppocr DEBUG: rec_res num  : 16, elapsed : 0.024315834045410156\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for image_name in os.listdir(args.input_dir):\n",
    "    image_path = f\"{args.input_dir}/{image_name}\"\n",
    "    img = Image.open(image_path)\n",
    "    w, h = img.size\n",
    "    results = ocr.ocr(image_path, cls=False)\n",
    "    result = results[0]\n",
    "    boxes = []\n",
    "    texts = []\n",
    "    if result is not None:\n",
    "        for line in result:\n",
    "            top_left, top_right, bottom_right, bottom_left = line[0]\n",
    "            x0, y0 = top_left\n",
    "            x1, y1 = bottom_right\n",
    "            x0 = x0 / w\n",
    "            y0 = y0 / h\n",
    "            x1 = x1 / w\n",
    "            y1 = y1 / h\n",
    "            boxes.append([x0, y0, x1, y1])\n",
    "            texts.append(line[1][0])\n",
    "    draw_img = visualize_bbox(img, boxes, texts)\n",
    "    draw_img.save(f\"{args.output_dir}/ocr_results/{image_name}\")\n",
    "    data.append({\"image_path\": image_path, \"image_name\": image_name, \"texts\": texts, \"boxes\": boxes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'MBart50Tokenizer'. \n",
      "The class this function is called from is 'XLMRobertaTokenizer'.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init weight of <facebook/mbart-large-50>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/mbart-large-50 were not used when initializing MBartForCausalLM: ['model.encoder.layers.6.self_attn.q_proj.bias', 'model.encoder.layers.1.self_attn.k_proj.bias', 'model.encoder.layers.0.fc1.bias', 'model.encoder.layers.4.fc1.bias', 'model.encoder.layernorm_embedding.bias', 'model.encoder.layers.3.self_attn.k_proj.bias', 'model.encoder.layers.9.fc2.bias', 'model.encoder.layers.9.self_attn.k_proj.weight', 'model.encoder.layers.10.self_attn.v_proj.weight', 'model.encoder.layers.6.final_layer_norm.weight', 'model.encoder.layers.5.self_attn.v_proj.bias', 'model.encoder.layers.4.self_attn_layer_norm.weight', 'model.encoder.layers.3.self_attn.q_proj.bias', 'model.encoder.layers.4.fc2.bias', 'model.encoder.layers.10.self_attn_layer_norm.bias', 'model.encoder.layers.2.final_layer_norm.weight', 'model.encoder.layers.0.fc2.bias', 'model.encoder.layers.9.self_attn.q_proj.bias', 'model.encoder.layers.4.self_attn.v_proj.weight', 'model.encoder.layers.11.self_attn.k_proj.bias', 'model.encoder.layers.1.final_layer_norm.weight', 'model.encoder.layers.3.fc1.weight', 'model.encoder.layer_norm.weight', 'model.encoder.layers.9.final_layer_norm.bias', 'model.encoder.layers.1.self_attn.k_proj.weight', 'model.encoder.layers.8.self_attn.k_proj.weight', 'model.encoder.layers.10.self_attn.out_proj.weight', 'model.encoder.layers.9.fc1.bias', 'model.encoder.layers.8.final_layer_norm.bias', 'model.encoder.layers.1.self_attn.out_proj.weight', 'model.encoder.layers.11.self_attn_layer_norm.weight', 'model.encoder.layers.10.final_layer_norm.weight', 'model.encoder.layers.5.self_attn.k_proj.bias', 'model.encoder.layers.1.self_attn_layer_norm.bias', 'model.encoder.layers.6.fc1.weight', 'model.encoder.layers.6.self_attn_layer_norm.weight', 'model.encoder.layers.2.fc2.bias', 'model.encoder.layers.9.self_attn.q_proj.weight', 'model.encoder.layers.10.self_attn.q_proj.weight', 'model.encoder.layers.7.fc2.weight', 'model.encoder.embed_positions.weight', 'model.encoder.layers.5.fc2.bias', 'model.encoder.layers.0.final_layer_norm.bias', 'model.encoder.layers.6.fc2.bias', 'model.encoder.layers.2.self_attn.k_proj.weight', 'model.encoder.layers.5.self_attn_layer_norm.bias', 'model.encoder.layers.4.self_attn.out_proj.bias', 'model.encoder.layers.0.fc1.weight', 'model.encoder.layers.7.final_layer_norm.weight', 'model.encoder.layers.1.self_attn.v_proj.bias', 'model.encoder.layers.7.fc1.bias', 'model.encoder.layers.1.final_layer_norm.bias', 'model.encoder.layers.7.self_attn.k_proj.weight', 'model.encoder.layers.4.self_attn.q_proj.weight', 'model.encoder.layers.8.self_attn.q_proj.weight', 'model.encoder.layers.10.self_attn.k_proj.bias', 'model.encoder.layers.11.fc1.weight', 'model.encoder.layers.3.final_layer_norm.bias', 'model.encoder.layers.6.self_attn.out_proj.bias', 'model.encoder.layers.10.fc1.bias', 'model.encoder.layers.10.fc2.weight', 'model.encoder.layers.0.self_attn.out_proj.bias', 'model.encoder.layers.4.self_attn.k_proj.weight', 'model.encoder.layers.8.self_attn_layer_norm.bias', 'model.encoder.layers.7.final_layer_norm.bias', 'model.encoder.layers.3.fc2.weight', 'model.encoder.layers.8.self_attn_layer_norm.weight', 'model.encoder.layers.4.self_attn.out_proj.weight', 'model.encoder.layers.11.final_layer_norm.weight', 'model.encoder.layers.9.self_attn.v_proj.weight', 'model.encoder.layers.1.self_attn.q_proj.weight', 'model.encoder.layers.7.self_attn.q_proj.weight', 'model.encoder.layers.0.self_attn_layer_norm.bias', 'model.encoder.layers.3.self_attn.q_proj.weight', 'model.encoder.layers.1.fc1.bias', 'model.encoder.layers.1.fc2.weight', 'model.encoder.layers.3.self_attn.k_proj.weight', 'model.encoder.layers.3.fc2.bias', 'model.encoder.layers.9.final_layer_norm.weight', 'model.encoder.layers.3.self_attn_layer_norm.bias', 'model.encoder.layers.10.fc2.bias', 'model.encoder.layers.0.self_attn.k_proj.bias', 'model.encoder.layers.5.self_attn.q_proj.weight', 'model.encoder.layers.11.self_attn.q_proj.bias', 'model.encoder.layers.4.final_layer_norm.bias', 'model.encoder.layers.3.self_attn.out_proj.weight', 'model.encoder.layers.8.fc2.weight', 'model.encoder.layers.5.fc1.weight', 'model.encoder.layers.4.self_attn_layer_norm.bias', 'model.encoder.layers.0.fc2.weight', 'model.encoder.layers.0.self_attn.out_proj.weight', 'model.encoder.layers.6.final_layer_norm.bias', 'model.encoder.layers.2.fc1.bias', 'model.encoder.layers.6.self_attn.v_proj.weight', 'model.encoder.layers.7.self_attn.q_proj.bias', 'model.encoder.layers.7.self_attn.out_proj.bias', 'model.encoder.layers.10.self_attn.k_proj.weight', 'model.encoder.layers.9.self_attn.v_proj.bias', 'model.encoder.layer_norm.bias', 'model.encoder.layers.10.self_attn.out_proj.bias', 'model.encoder.layers.9.fc1.weight', 'model.encoder.layers.5.self_attn.out_proj.bias', 'model.encoder.layers.2.self_attn.out_proj.bias', 'model.encoder.layers.2.self_attn.q_proj.weight', 'model.encoder.layers.6.fc2.weight', 'model.encoder.layers.3.fc1.bias', 'model.encoder.layers.5.final_layer_norm.weight', 'model.encoder.layers.11.fc2.bias', 'model.encoder.layers.6.fc1.bias', 'model.encoder.layers.0.self_attn_layer_norm.weight', 'model.encoder.layers.5.self_attn_layer_norm.weight', 'model.encoder.layers.4.self_attn.q_proj.bias', 'model.encoder.layers.10.self_attn.v_proj.bias', 'model.encoder.layers.8.self_attn.out_proj.weight', 'model.encoder.layers.10.fc1.weight', 'model.encoder.layers.4.self_attn.k_proj.bias', 'model.encoder.layers.1.fc2.bias', 'model.encoder.layers.3.self_attn_layer_norm.weight', 'model.encoder.layers.4.fc1.weight', 'model.encoder.layers.0.self_attn.q_proj.weight', 'model.encoder.layers.9.fc2.weight', 'model.encoder.layers.11.fc1.bias', 'model.encoder.layers.10.final_layer_norm.bias', 'model.encoder.layers.8.self_attn.k_proj.bias', 'model.encoder.layers.0.self_attn.k_proj.weight', 'model.encoder.layers.3.final_layer_norm.weight', 'model.encoder.layers.4.self_attn.v_proj.bias', 'model.shared.weight', 'model.encoder.layers.4.final_layer_norm.weight', 'model.encoder.layers.0.self_attn.v_proj.weight', 'model.encoder.layers.11.self_attn.out_proj.weight', 'model.encoder.layers.2.self_attn_layer_norm.bias', 'model.encoder.layers.7.self_attn_layer_norm.weight', 'model.encoder.layers.11.self_attn.q_proj.weight', 'model.encoder.layers.2.self_attn.q_proj.bias', 'model.encoder.layers.7.self_attn.v_proj.weight', 'model.encoder.layers.4.fc2.weight', 'model.encoder.layers.3.self_attn.v_proj.weight', 'model.encoder.layers.11.self_attn.k_proj.weight', 'model.encoder.layernorm_embedding.weight', 'model.encoder.layers.3.self_attn.v_proj.bias', 'model.encoder.layers.10.self_attn.q_proj.bias', 'model.encoder.layers.5.self_attn.q_proj.bias', 'model.encoder.layers.9.self_attn.out_proj.bias', 'model.encoder.layers.6.self_attn.out_proj.weight', 'model.encoder.layers.6.self_attn_layer_norm.bias', 'model.encoder.layers.8.fc1.bias', 'model.encoder.layers.2.self_attn.out_proj.weight', 'model.encoder.layers.6.self_attn.k_proj.bias', 'model.encoder.layers.2.fc2.weight', 'model.encoder.layers.11.self_attn.v_proj.bias', 'model.encoder.layers.7.self_attn.k_proj.bias', 'model.encoder.layers.5.final_layer_norm.bias', 'model.encoder.layers.2.fc1.weight', 'model.encoder.layers.8.self_attn.out_proj.bias', 'model.encoder.layers.6.self_attn.v_proj.bias', 'model.encoder.layers.1.fc1.weight', 'model.encoder.layers.0.final_layer_norm.weight', 'model.encoder.layers.11.self_attn.v_proj.weight', 'model.encoder.layers.6.self_attn.k_proj.weight', 'model.encoder.layers.8.self_attn.q_proj.bias', 'model.encoder.layers.1.self_attn.q_proj.bias', 'model.encoder.layers.7.self_attn.out_proj.weight', 'model.encoder.layers.1.self_attn.v_proj.weight', 'model.encoder.layers.8.final_layer_norm.weight', 'final_logits_bias', 'model.encoder.layers.7.fc2.bias', 'model.encoder.layers.1.self_attn.out_proj.bias', 'model.encoder.embed_tokens.weight', 'model.encoder.layers.3.self_attn.out_proj.bias', 'model.encoder.layers.7.self_attn_layer_norm.bias', 'model.encoder.layers.2.self_attn.k_proj.bias', 'model.encoder.layers.2.self_attn.v_proj.bias', 'model.encoder.layers.11.final_layer_norm.bias', 'model.encoder.layers.5.fc1.bias', 'model.encoder.layers.5.self_attn.k_proj.weight', 'model.encoder.layers.8.fc2.bias', 'model.encoder.layers.1.self_attn_layer_norm.weight', 'model.encoder.layers.11.fc2.weight', 'model.encoder.layers.8.self_attn.v_proj.bias', 'model.encoder.layers.7.self_attn.v_proj.bias', 'model.encoder.layers.9.self_attn.k_proj.bias', 'model.encoder.layers.11.self_attn.out_proj.bias', 'model.encoder.layers.0.self_attn.v_proj.bias', 'model.encoder.layers.9.self_attn.out_proj.weight', 'model.encoder.layers.10.self_attn_layer_norm.weight', 'model.encoder.layers.2.final_layer_norm.bias', 'model.encoder.layers.5.self_attn.v_proj.weight', 'model.encoder.layers.0.self_attn.q_proj.bias', 'model.encoder.layers.8.fc1.weight', 'model.encoder.layers.2.self_attn_layer_norm.weight', 'model.encoder.layers.8.self_attn.v_proj.weight', 'model.encoder.layers.5.self_attn.out_proj.weight', 'model.encoder.layers.11.self_attn_layer_norm.bias', 'model.encoder.layers.5.fc2.weight', 'model.encoder.layers.6.self_attn.q_proj.weight', 'model.encoder.layers.9.self_attn_layer_norm.weight', 'model.encoder.layers.2.self_attn.v_proj.weight', 'model.encoder.layers.9.self_attn_layer_norm.bias', 'model.encoder.layers.7.fc1.weight']\n",
      "- This IS expected if you are initializing MBartForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MBartForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.decoder.embed_positions.weight\n"
     ]
    }
   ],
   "source": [
    "### model download\n",
    "model = build_model(args.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250055"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.decoder.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data_layoutlm(model, data):\n",
    "    #tokenizer\n",
    "    encoder_processor = model.encoder.prepare_input\n",
    "    for sample in data:\n",
    "        image = Image.open(sample[\"image_path\"])\n",
    "        encoder_encoding = encoder_processor(image, sample[\"texts\"], bboxes=sample[\"boxes\"])\n",
    "        encoder_encoding[\"bbox\"] = (encoder_encoding[\"bbox\"]*1000).to(torch.int32)\n",
    "        sample[\"encoding_inputs\"] = encoder_encoding\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data_swin(model, data):\n",
    "    #tokenizer\n",
    "    encoder_processor = model.encoder.prepare_input\n",
    "    for sample in data:\n",
    "        image = Image.open(sample[\"image_path\"])\n",
    "        encoder_encoding = encoder_processor(image)\n",
    "        sample[\"encoding_inputs\"] = encoder_encoding\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = preprocessing_data(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'image_path': 'example/100.png',\n",
       "  'image_name': '100.png',\n",
       "  'texts': ['Subsidiary',\n",
       "   'Medtronic',\n",
       "   'Medtronic,',\n",
       "   'Medtronic',\n",
       "   'Non-',\n",
       "   'Consolidating',\n",
       "   'plc',\n",
       "   'Inc.',\n",
       "   'Luxco',\n",
       "   'guarantors',\n",
       "   'Adjustments',\n",
       "   'Total',\n",
       "   'Net sales',\n",
       "   '$',\n",
       "   '1,261',\n",
       "   'S',\n",
       "   '$',\n",
       "   '20,261',\n",
       "   '$',\n",
       "   '(1,261) $',\n",
       "   '20,261',\n",
       "   'Costs and expenses:',\n",
       "   'Cost of products sold',\n",
       "   '895',\n",
       "   '6,659',\n",
       "   '{1,245)',\n",
       "   '6,309',\n",
       "   'Research and development expense',\n",
       "   '552',\n",
       "   '1,088',\n",
       "   '1,640',\n",
       "   'Selling, general, and administrative expense',\n",
       "   '1',\n",
       "   '857',\n",
       "   '6,046',\n",
       "   '6,904',\n",
       "   'Special charge (gain), net',\n",
       "   '100',\n",
       "   '(138)',\n",
       "   '(38)',\n",
       "   'Restructuring charges, net',\n",
       "   '7',\n",
       "   '230',\n",
       "   '237',\n",
       "   'Certain litigation charges',\n",
       "   '42',\n",
       "   '42',\n",
       "   'Acquisition-related items',\n",
       "   '312',\n",
       "   '238',\n",
       "   ' 550',\n",
       "   'Amortization of intangible assets',\n",
       "   '11',\n",
       "   '722',\n",
       "   '733',\n",
       "   'Other expense (income), net',\n",
       "   '103',\n",
       "   '(1,618)',\n",
       "   '1,633',\n",
       "   '118',\n",
       "   'Operating (loss) profit',\n",
       "   '(104)',\n",
       "   '145',\n",
       "   '3,741',\n",
       "   '(16)',\n",
       "   '3,766',\n",
       "   'Interest income',\n",
       "   '(56)',\n",
       "   '(170)',\n",
       "   '(387)',\n",
       "   '227',\n",
       "   '(386)',\n",
       "   'Interest expense',\n",
       "   '762',\n",
       "   '\\\\',\n",
       "   '131',\n",
       "   '(227)',\n",
       "   '666',\n",
       "   'Interest expense (income), net',\n",
       "   '706',\n",
       "   '(170)',\n",
       "   '(256)',\n",
       "   '280',\n",
       "   'Equity in net (income) loss of subsidiaries',\n",
       "   '(2,790)',\n",
       "   '(5,500)',\n",
       "   '(2,620)',\n",
       "   '10,910',\n",
       "   'Income (loss) from operations before income taxes',\n",
       "   '2,686',\n",
       "   '4,939',\n",
       "   '2,790',\n",
       "   '3,997',\n",
       "   '(10,926)',\n",
       "   '3,486',\n",
       "   'Provision (benefit) for income taxes',\n",
       "   '11',\n",
       "   '(44)',\n",
       "   '844',\n",
       "   '811',\n",
       "   'Net income',\n",
       "   '2,675',\n",
       "   '4,983',\n",
       "   '2,790',\n",
       "   '3,153',\n",
       "   '(10,926)',\n",
       "   '2,675',\n",
       "   'Other comprehensive income (loss), net of tax',\n",
       "   '(587)',\n",
       "   '(542)',\n",
       "   '(587)',\n",
       "   '(232)',\n",
       "   '1,361',\n",
       "   '(587)',\n",
       "   'TOTAL COMPREHENSIVE INCOME (LOSS)',\n",
       "   '$',\n",
       "   '2,088',\n",
       "   '$',\n",
       "   '4,441',\n",
       "   '$',\n",
       "   '2,203',\n",
       "   '2,921',\n",
       "   '$',\n",
       "   '(9,565) $',\n",
       "   '2,088'],\n",
       "  'boxes': [[0.7058823529411765,\n",
       "    0.002364066193853428,\n",
       "    0.7794117647058824,\n",
       "    0.03546099290780142],\n",
       "   [0.3911764705882353,\n",
       "    0.03309692671394799,\n",
       "    0.4647058823529412,\n",
       "    0.06619385342789598],\n",
       "   [0.49117647058823527,\n",
       "    0.028368794326241134,\n",
       "    0.5676470588235294,\n",
       "    0.07092198581560284],\n",
       "   [0.6014705882352941, 0.03309692671394799, 0.675, 0.06619385342789598],\n",
       "   [0.7426470588235294,\n",
       "    0.03546099290780142,\n",
       "    0.7794117647058824,\n",
       "    0.06382978723404255],\n",
       "   [0.7955882352941176,\n",
       "    0.026004728132387706,\n",
       "    0.8911764705882353,\n",
       "    0.07092198581560284],\n",
       "   [0.4426470588235294,\n",
       "    0.06619385342789598,\n",
       "    0.4647058823529412,\n",
       "    0.09929078014184398],\n",
       "   [0.5411764705882353,\n",
       "    0.06382978723404255,\n",
       "    0.5676470588235294,\n",
       "    0.09692671394799054],\n",
       "   [0.6308823529411764,\n",
       "    0.06619385342789598,\n",
       "    0.6735294117647059,\n",
       "    0.09456264775413711],\n",
       "   [0.7073529411764706,\n",
       "    0.06855791962174941,\n",
       "    0.7779411764705882,\n",
       "    0.09456264775413711],\n",
       "   [0.8014705882352942,\n",
       "    0.06619385342789598,\n",
       "    0.8867647058823529,\n",
       "    0.09456264775413711],\n",
       "   [0.9602941176470589,\n",
       "    0.05673758865248227,\n",
       "    0.9970588235294118,\n",
       "    0.1016548463356974],\n",
       "   [0.0029411764705882353,\n",
       "    0.10401891252955082,\n",
       "    0.07205882352941176,\n",
       "    0.13947990543735225],\n",
       "   [0.47352941176470587,\n",
       "    0.1016548463356974,\n",
       "    0.48676470588235293,\n",
       "    0.13238770685579196],\n",
       "   [0.5264705882352941,\n",
       "    0.09456264775413711,\n",
       "    0.5808823529411765,\n",
       "    0.13711583924349882],\n",
       "   [0.5794117647058824,\n",
       "    0.1016548463356974,\n",
       "    0.5911764705882353,\n",
       "    0.13238770685579196],\n",
       "   [0.6838235294117647,\n",
       "    0.1016548463356974,\n",
       "    0.6985294117647058,\n",
       "    0.13238770685579196],\n",
       "   [0.7294117647058823,\n",
       "    0.09929078014184398,\n",
       "    0.7838235294117647,\n",
       "    0.1347517730496454],\n",
       "   [0.788235294117647,\n",
       "    0.1016548463356974,\n",
       "    0.8014705882352942,\n",
       "    0.13002364066193853],\n",
       "   [0.8455882352941176,\n",
       "    0.09929078014184398,\n",
       "    0.9147058823529411,\n",
       "    0.1347517730496454],\n",
       "   [0.9470588235294117,\n",
       "    0.09929078014184398,\n",
       "    0.9985294117647059,\n",
       "    0.1347517730496454],\n",
       "   [0.004411764705882353,\n",
       "    0.14657210401891252,\n",
       "    0.14558823529411766,\n",
       "    0.17966903073286053],\n",
       "   [0.01911764705882353,\n",
       "    0.19148936170212766,\n",
       "    0.16470588235294117,\n",
       "    0.22458628841607564],\n",
       "   [0.5367647058823529,\n",
       "    0.18912529550827423,\n",
       "    0.5720588235294117,\n",
       "    0.2293144208037825],\n",
       "   [0.7382352941176471,\n",
       "    0.18912529550827423,\n",
       "    0.7808823529411765,\n",
       "    0.2293144208037825],\n",
       "   [0.8441176470588235,\n",
       "    0.1867612293144208,\n",
       "    0.8985294117647059,\n",
       "    0.23167848699763594],\n",
       "   [0.9558823529411765,\n",
       "    0.18912529550827423,\n",
       "    0.9985294117647059,\n",
       "    0.2293144208037825],\n",
       "   [0.01911764705882353,\n",
       "    0.23404255319148937,\n",
       "    0.26029411764705884,\n",
       "    0.2647754137115839],\n",
       "   [0.5367647058823529,\n",
       "    0.2293144208037825,\n",
       "    0.5720588235294117,\n",
       "    0.2695035460992908],\n",
       "   [0.7397058823529412,\n",
       "    0.23167848699763594,\n",
       "    0.7808823529411765,\n",
       "    0.26713947990543735],\n",
       "   [0.9558823529411765,\n",
       "    0.23167848699763594,\n",
       "    0.9985294117647059,\n",
       "    0.2695035460992908],\n",
       "   [0.01911764705882353,\n",
       "    0.2765957446808511,\n",
       "    0.3044117647058823,\n",
       "    0.30969267139479906],\n",
       "   [0.4485294117647059,\n",
       "    0.2718676122931442,\n",
       "    0.4676470588235294,\n",
       "    0.3144208037825059],\n",
       "   [0.5367647058823529,\n",
       "    0.2718676122931442,\n",
       "    0.5705882352941176,\n",
       "    0.3120567375886525],\n",
       "   [0.7382352941176471,\n",
       "    0.2718676122931442,\n",
       "    0.7823529411764706,\n",
       "    0.30969267139479906],\n",
       "   [0.9558823529411765,\n",
       "    0.27423167848699764,\n",
       "    0.9985294117647059,\n",
       "    0.3120567375886525],\n",
       "   [0.01911764705882353,\n",
       "    0.3191489361702128,\n",
       "    0.18823529411764706,\n",
       "    0.34988179669030733],\n",
       "   [0.538235294117647,\n",
       "    0.3144208037825059,\n",
       "    0.5720588235294117,\n",
       "    0.3546099290780142],\n",
       "   [0.7470588235294118,\n",
       "    0.3144208037825059,\n",
       "    0.7852941176470588,\n",
       "    0.35224586288416077],\n",
       "   [0.9691176470588235,\n",
       "    0.3144208037825059,\n",
       "    0.9985294117647059,\n",
       "    0.3546099290780142],\n",
       "   [0.01911764705882353,\n",
       "    0.3617021276595745,\n",
       "    0.19852941176470587,\n",
       "    0.3947990543735225],\n",
       "   [0.5544117647058824,\n",
       "    0.35933806146572106,\n",
       "    0.5720588235294117,\n",
       "    0.39952718676122934],\n",
       "   [0.75, 0.3546099290780142, 0.7823529411764706, 0.3971631205673759],\n",
       "   [0.9661764705882353,\n",
       "    0.35933806146572106,\n",
       "    0.9985294117647059,\n",
       "    0.39952718676122934],\n",
       "   [0.01911764705882353,\n",
       "    0.39952718676122934,\n",
       "    0.18529411764705883,\n",
       "    0.43498817966903075],\n",
       "   [0.7573529411764706,\n",
       "    0.3971631205673759,\n",
       "    0.7823529411764706,\n",
       "    0.4397163120567376],\n",
       "   [0.9735294117647059,\n",
       "    0.39952718676122934,\n",
       "    0.9985294117647059,\n",
       "    0.4397163120567376],\n",
       "   [0.020588235294117647,\n",
       "    0.44680851063829785,\n",
       "    0.18823529411764706,\n",
       "    0.47044917257683216],\n",
       "   [0.538235294117647,\n",
       "    0.4373522458628842,\n",
       "    0.5720588235294117,\n",
       "    0.4799054373522459],\n",
       "   [0.7485294117647059,\n",
       "    0.4397163120567376,\n",
       "    0.7823529411764706,\n",
       "    0.4799054373522459],\n",
       "   [0.9661764705882353,\n",
       "    0.4397163120567376,\n",
       "    0.9985294117647059,\n",
       "    0.4799054373522459],\n",
       "   [0.020588235294117647,\n",
       "    0.4846335697399527,\n",
       "    0.23823529411764705,\n",
       "    0.5177304964539007],\n",
       "   [0.5455882352941176,\n",
       "    0.4799054373522459,\n",
       "    0.5720588235294117,\n",
       "    0.524822695035461],\n",
       "   [0.75, 0.4799054373522459, 0.7808823529411765, 0.5224586288416075],\n",
       "   [0.9661764705882353,\n",
       "    0.48226950354609927,\n",
       "    0.9985294117647059,\n",
       "    0.524822695035461],\n",
       "   [0.01764705882352941,\n",
       "    0.524822695035461,\n",
       "    0.21323529411764705,\n",
       "    0.5602836879432624],\n",
       "   [0.4323529411764706,\n",
       "    0.5224586288416075,\n",
       "    0.4661764705882353,\n",
       "    0.5626477541371159],\n",
       "   [0.5205882352941177,\n",
       "    0.5224586288416075,\n",
       "    0.5764705882352941,\n",
       "    0.5650118203309693],\n",
       "   [0.7397058823529412,\n",
       "    0.524822695035461,\n",
       "    0.7808823529411765,\n",
       "    0.5626477541371159],\n",
       "   [0.9661764705882353,\n",
       "    0.524822695035461,\n",
       "    0.9985294117647059,\n",
       "    0.5650118203309693],\n",
       "   [0.004411764705882353,\n",
       "    0.5721040189125296,\n",
       "    0.15588235294117647,\n",
       "    0.6052009456264775],\n",
       "   [0.4279411764705882,\n",
       "    0.5673758865248227,\n",
       "    0.46911764705882353,\n",
       "    0.6052009456264775],\n",
       "   [0.5367647058823529,\n",
       "    0.5673758865248227,\n",
       "    0.5720588235294117,\n",
       "    0.6052009456264775],\n",
       "   [0.7382352941176471,\n",
       "    0.5673758865248227,\n",
       "    0.7808823529411765,\n",
       "    0.6052009456264775],\n",
       "   [0.8647058823529412,\n",
       "    0.5673758865248227,\n",
       "    0.8970588235294118,\n",
       "    0.6052009456264775],\n",
       "   [0.9558823529411765,\n",
       "    0.5697399527186762,\n",
       "    0.9985294117647059,\n",
       "    0.6052009456264775],\n",
       "   [0.01764705882352941,\n",
       "    0.6122931442080378,\n",
       "    0.1264705882352941,\n",
       "    0.6524822695035462],\n",
       "   [0.5426470588235294,\n",
       "    0.6099290780141844,\n",
       "    0.5764705882352941,\n",
       "    0.6524822695035462],\n",
       "   [0.6397058823529411,\n",
       "    0.6122931442080378,\n",
       "    0.6794117647058824,\n",
       "    0.6524822695035462],\n",
       "   [0.7470588235294118,\n",
       "    0.6122931442080378,\n",
       "    0.7852941176470588,\n",
       "    0.6524822695035462],\n",
       "   [0.8602941176470589,\n",
       "    0.6099290780141844,\n",
       "    0.8926470588235295,\n",
       "    0.6524822695035462],\n",
       "   [0.9632352941176471,\n",
       "    0.6122931442080378,\n",
       "    0.9985294117647059,\n",
       "    0.6524822695035462],\n",
       "   [0.020588235294117647,\n",
       "    0.6619385342789598,\n",
       "    0.1323529411764706,\n",
       "    0.6879432624113475],\n",
       "   [0.5367647058823529,\n",
       "    0.6548463356973995,\n",
       "    0.5720588235294117,\n",
       "    0.6926713947990544],\n",
       "   [0.6529411764705882,\n",
       "    0.6643026004728132,\n",
       "    0.6779411764705883,\n",
       "    0.6784869976359338],\n",
       "   [0.75, 0.6548463356973995, 0.7808823529411765, 0.6926713947990544],\n",
       "   [0.8573529411764705,\n",
       "    0.6548463356973995,\n",
       "    0.8970588235294118,\n",
       "    0.6926713947990544],\n",
       "   [0.9661764705882353,\n",
       "    0.6501182033096927,\n",
       "    0.9985294117647059,\n",
       "    0.6973995271867612],\n",
       "   [0.030882352941176472,\n",
       "    0.7021276595744681,\n",
       "    0.24411764705882352,\n",
       "    0.7328605200945626],\n",
       "   [0.538235294117647,\n",
       "    0.6973995271867612,\n",
       "    0.5720588235294117,\n",
       "    0.735224586288416],\n",
       "   [0.6397058823529411,\n",
       "    0.6950354609929078,\n",
       "    0.6794117647058824,\n",
       "    0.7328605200945626],\n",
       "   [0.7470588235294118,\n",
       "    0.6950354609929078,\n",
       "    0.7852941176470588,\n",
       "    0.7328605200945626],\n",
       "   [0.9661764705882353,\n",
       "    0.6973995271867612,\n",
       "    0.9985294117647059,\n",
       "    0.735224586288416],\n",
       "   [0.01911764705882353,\n",
       "    0.7446808510638298,\n",
       "    0.2897058823529412,\n",
       "    0.7754137115839244],\n",
       "   [0.4176470588235294,\n",
       "    0.7423167848699763,\n",
       "    0.46911764705882353,\n",
       "    0.7777777777777778],\n",
       "   [0.5220588235294118, 0.7423167848699763, 0.575, 0.7777777777777778],\n",
       "   [0.6294117647058823,\n",
       "    0.7423167848699763,\n",
       "    0.6794117647058824,\n",
       "    0.7777777777777778],\n",
       "   [0.8426470588235294,\n",
       "    0.7423167848699763,\n",
       "    0.8941176470588236,\n",
       "    0.7777777777777778],\n",
       "   [0.004411764705882353,\n",
       "    0.7919621749408984,\n",
       "    0.34705882352941175,\n",
       "    0.8226950354609929],\n",
       "   [0.42058823529411765,\n",
       "    0.7825059101654847,\n",
       "    0.4661764705882353,\n",
       "    0.8203309692671394],\n",
       "   [0.5279411764705882,\n",
       "    0.7825059101654847,\n",
       "    0.5720588235294117,\n",
       "    0.8226950354609929],\n",
       "   [0.6338235294117647, 0.7825059101654847, 0.675, 0.8226950354609929],\n",
       "   [0.7382352941176471,\n",
       "    0.7801418439716312,\n",
       "    0.7808823529411765,\n",
       "    0.8203309692671394],\n",
       "   [0.8382352941176471,\n",
       "    0.7825059101654847,\n",
       "    0.8955882352941177,\n",
       "    0.8203309692671394],\n",
       "   [0.9558823529411765,\n",
       "    0.7825059101654847,\n",
       "    0.9985294117647059,\n",
       "    0.8226950354609929],\n",
       "   [0.004411764705882353,\n",
       "    0.8392434988179669,\n",
       "    0.2426470588235294,\n",
       "    0.8628841607565012],\n",
       "   [0.4411764705882353,\n",
       "    0.8274231678486997,\n",
       "    0.4676470588235294,\n",
       "    0.8699763593380615],\n",
       "   [0.5411764705882353,\n",
       "    0.8297872340425532,\n",
       "    0.5764705882352941,\n",
       "    0.8676122931442081],\n",
       "   [0.7485294117647059,\n",
       "    0.8297872340425532,\n",
       "    0.7823529411764706,\n",
       "    0.8676122931442081],\n",
       "   [0.9661764705882353,\n",
       "    0.8297872340425532,\n",
       "    0.9985294117647059,\n",
       "    0.8699763593380615],\n",
       "   [0.030882352941176472,\n",
       "    0.8794326241134752,\n",
       "    0.11470588235294117,\n",
       "    0.9125295508274232],\n",
       "   [0.42058823529411765,\n",
       "    0.8770685579196218,\n",
       "    0.4661764705882353,\n",
       "    0.9125295508274232],\n",
       "   [0.5279411764705882,\n",
       "    0.8770685579196218,\n",
       "    0.5720588235294117,\n",
       "    0.9125295508274232],\n",
       "   [0.6323529411764706, 0.8747044917257684, 0.675, 0.9125295508274232],\n",
       "   [0.7382352941176471,\n",
       "    0.8747044917257684,\n",
       "    0.7808823529411765,\n",
       "    0.9125295508274232],\n",
       "   [0.8382352941176471,\n",
       "    0.8770685579196218,\n",
       "    0.8970588235294118,\n",
       "    0.9101654846335697],\n",
       "   [0.9558823529411765,\n",
       "    0.8770685579196218,\n",
       "    0.9985294117647059,\n",
       "    0.9125295508274232],\n",
       "   [0.0029411764705882353,\n",
       "    0.9219858156028369,\n",
       "    0.3014705882352941,\n",
       "    0.9550827423167849],\n",
       "   [0.4279411764705882,\n",
       "    0.9196217494089834,\n",
       "    0.47058823529411764,\n",
       "    0.9574468085106383],\n",
       "   [0.5338235294117647, 0.91725768321513, 0.575, 0.9574468085106383],\n",
       "   [0.6397058823529411,\n",
       "    0.9196217494089834,\n",
       "    0.6808823529411765,\n",
       "    0.9574468085106383],\n",
       "   [0.7470588235294118,\n",
       "    0.91725768321513,\n",
       "    0.7867647058823529,\n",
       "    0.9574468085106383],\n",
       "   [0.8485294117647059,\n",
       "    0.9196217494089834,\n",
       "    0.8926470588235295,\n",
       "    0.9574468085106383],\n",
       "   [0.961764705882353,\n",
       "    0.9196217494089834,\n",
       "    0.9985294117647059,\n",
       "    0.9598108747044918],\n",
       "   [0.03235294117647059,\n",
       "    0.9645390070921985,\n",
       "    0.3176470588235294,\n",
       "    0.9976359338061466],\n",
       "   [0.36764705882352944,\n",
       "    0.966903073286052,\n",
       "    0.38088235294117645,\n",
       "    0.9976359338061466],\n",
       "   [0.41911764705882354,\n",
       "    0.9645390070921985,\n",
       "    0.46911764705882353,\n",
       "    0.9976359338061466],\n",
       "   [0.47205882352941175,\n",
       "    0.9692671394799054,\n",
       "    0.4838235294117647,\n",
       "    0.9952718676122931],\n",
       "   [0.5264705882352941,\n",
       "    0.9645390070921985,\n",
       "    0.5764705882352941,\n",
       "    0.9976359338061466],\n",
       "   [0.5779411764705882,\n",
       "    0.966903073286052,\n",
       "    0.5911764705882353,\n",
       "    0.9929078014184397],\n",
       "   [0.6323529411764706,\n",
       "    0.9645390070921985,\n",
       "    0.6823529411764706,\n",
       "    0.9976359338061466],\n",
       "   [0.736764705882353,\n",
       "    0.9645390070921985,\n",
       "    0.7838235294117647,\n",
       "    0.9976359338061466],\n",
       "   [0.788235294117647,\n",
       "    0.966903073286052,\n",
       "    0.8014705882352942,\n",
       "    0.9952718676122931],\n",
       "   [0.8441176470588235,\n",
       "    0.9645390070921985,\n",
       "    0.9147058823529411,\n",
       "    0.9976359338061466],\n",
       "   [0.9544117647058824,\n",
       "    0.9645390070921985,\n",
       "    0.9985294117647059,\n",
       "    0.9976359338061466]],\n",
       "  'encoding_inputs': tensor([[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "           ...,\n",
       "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
       "  \n",
       "          [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "           ...,\n",
       "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
       "  \n",
       "          [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "           ...,\n",
       "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]])},\n",
       " {'image_path': 'example/test_2.png',\n",
       "  'image_name': 'test_2.png',\n",
       "  'texts': ['10',\n",
       "   '120',\n",
       "   '140',\n",
       "   'precision (%)',\n",
       "   '72.92',\n",
       "   '65.96',\n",
       "   '47.92',\n",
       "   'recall (%)',\n",
       "   '85.37',\n",
       "   '96.88',\n",
       "   '100.00',\n",
       "   'f-measure(%)',\n",
       "   '84.34',\n",
       "   '78.48',\n",
       "   '64.79'],\n",
       "  'boxes': [[0.43142857142857144, 0.075, 0.5, 0.25833333333333336],\n",
       "   [0.6414285714285715, 0.075, 0.71, 0.25833333333333336],\n",
       "   [0.8542857142857143, 0.075, 0.9214285714285714, 0.25833333333333336],\n",
       "   [0.06, 0.3333333333333333, 0.30857142857142855, 0.49166666666666664],\n",
       "   [0.4142857142857143, 0.325, 0.5171428571428571, 0.5],\n",
       "   [0.6257142857142857, 0.3333333333333333, 0.7285714285714285, 0.5],\n",
       "   [0.8342857142857143, 0.3333333333333333, 0.9385714285714286, 0.5],\n",
       "   [0.09142857142857143, 0.5583333333333333, 0.27714285714285714, 0.725],\n",
       "   [0.4114285714285714,\n",
       "    0.5666666666666667,\n",
       "    0.5171428571428571,\n",
       "    0.7333333333333333],\n",
       "   [0.6228571428571429, 0.55, 0.7285714285714285, 0.7416666666666667],\n",
       "   [0.8257142857142857, 0.5416666666666666, 0.95, 0.7333333333333333],\n",
       "   [0.05, 0.8, 0.31857142857142856, 0.9583333333333334],\n",
       "   [0.4114285714285714, 0.8, 0.52, 0.9666666666666667],\n",
       "   [0.6257142857142857, 0.8, 0.73, 0.9666666666666667],\n",
       "   [0.8357142857142857, 0.8, 0.94, 0.9666666666666667]],\n",
       "  'encoding_inputs': tensor([[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "           ...,\n",
       "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
       "  \n",
       "          [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "           ...,\n",
       "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
       "  \n",
       "          [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "           ...,\n",
       "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]])}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "generations = []\n",
    "for sample in dataset:\n",
    "    inputs = sample[\"encoding_inputs\"].unsqueeze(0)\n",
    "    generate_text = model.inference(image_tensors=inputs)[\"predictions\"]\n",
    "    generations.append({\"image_name\": sample[\"image_name\"], \"generation\": generate_text[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 3, 448, 896])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in generations:\n",
    "  with open(f\"{args.output_dir}/model_predictions/{sample['image_name']}.txt\", \"w\") as f:\n",
    "    f.write(str(sample[\"generation\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table><thead><tr><td><b><i>Î±</i></b></td><td><b>1</b></td><td><b>12</b></td><td><b>14</b></td></tr></thead><tbody><tr><td><b>precision</b><b>(%)</b></td><td>72.92</td><td>65.96</td><td>47.92</td></tr><tr><td><b>recall</b><b>(%)</b></td><td>85.37</td><td>96.88</td><td>100.00</td></tr><tr><td><b><i><b>f</i></b><b>-measure</b><b>(%)</b></td><td>84.34</td><td>78.48</td><td>64.79</td></tr></tbody></table>'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = generations[1][\"generation\"][0]\n",
    "html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><thead><tr><td><b><i>Î±</i></b></td><td><b>1</b></td><td><b>2</b></td><td><b>1</b></td></tr></thead><tbody><tr><td><b>precision (%)</b></td><td>72.92</td><td>65.96</td><td>47.92</td></tr><tr><td><b>recall (%)</b></td><td>85.37</td><td>96.88</td><td>100.00</td></tr><tr><td><b>f-measure(%)</b></td><td>84.34</td><td>78.48</td><td>64.79</td></tr></tbody></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_table  = HTML(format_html(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IPython.core.display.HTML"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(html_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       " <head>\n",
       "  <meta charset=\"utf-8\"/>\n",
       "  <style>\n",
       "   table, th, td {\n",
       "                     border: 1px solid black;\n",
       "                     font-size: 20px;\n",
       "                   }\n",
       "  </style>\n",
       " </head>\n",
       " <body>\n",
       "  <table frame=\"hsides\" rules=\"groups\" width=\"100%\">\n",
       "   <table>\n",
       "    <thead>\n",
       "     <tr>\n",
       "      <td>\n",
       "      </td>\n",
       "      <td>\n",
       "       <b>\n",
       "        Mediatronic,\n",
       "       </b>\n",
       "      </td>\n",
       "      <td>\n",
       "       <b>\n",
       "        Medtronic,\n",
       "       </b>\n",
       "      </td>\n",
       "      <td>\n",
       "       <b>\n",
       "        Medtronic,\n",
       "       </b>\n",
       "      </td>\n",
       "      <td>\n",
       "       <b>\n",
       "        Semiary\n",
       "       </b>\n",
       "      </td>\n",
       "      <td>\n",
       "       <b>\n",
       "        Consoliddating\n",
       "       </b>\n",
       "      </td>\n",
       "      <td>\n",
       "       <b>\n",
       "        Consolidating\n",
       "       </b>\n",
       "      </td>\n",
       "      <td>\n",
       "       <b>\n",
       "        Total\n",
       "       </b>\n",
       "      </td>\n",
       "     </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "     <tr>\n",
       "      <td>\n",
       "       Costs sold\n",
       "      </td>\n",
       "      <td>\n",
       "       1\n",
       "      </td>\n",
       "      <td>\n",
       "       1,261\n",
       "      </td>\n",
       "      <td>\n",
       "       5\n",
       "      </td>\n",
       "      <td>\n",
       "       0,659\n",
       "      </td>\n",
       "      <td>\n",
       "       1,245\n",
       "      </td>\n",
       "      <td>\n",
       "       1,245\n",
       "      </td>\n",
       "      <td>\n",
       "       1,360\n",
       "      </td>\n",
       "     </tr>\n",
       "     <tr>\n",
       "      <td>\n",
       "       Research and development expenses\n",
       "      </td>\n",
       "      <td>\n",
       "       1\n",
       "      </td>\n",
       "      <td>\n",
       "       1\n",
       "      </td>\n",
       "      <td>\n",
       "       552\n",
       "      </td>\n",
       "      <td>\n",
       "       1,586\n",
       "      </td>\n",
       "      <td>\n",
       "       1,044\n",
       "      </td>\n",
       "      <td>\n",
       "       1,645\n",
       "      </td>\n",
       "      <td>\n",
       "       1,900\n",
       "      </td>\n",
       "     </tr>\n",
       "     <tr>\n",
       "      <td>\n",
       "       Acquisition-related items\n",
       "      </td>\n",
       "      <td>\n",
       "       Other expense (income), net\n",
       "      </td>\n",
       "      <td>\n",
       "       1034\n",
       "      </td>\n",
       "      <td>\n",
       "       145\n",
       "      </td>\n",
       "      <td>\n",
       "       (56)\n",
       "      </td>\n",
       "      <td>\n",
       "       3,734\n",
       "      </td>\n",
       "      <td>\n",
       "       (16)\n",
       "      </td>\n",
       "      <td>\n",
       "       7,726\n",
       "      </td>\n",
       "     </tr>\n",
       "     <tr>\n",
       "      <td>\n",
       "       Indirected inactivity\n",
       "      </td>\n",
       "      <td>\n",
       "       1\n",
       "      </td>\n",
       "      <td>\n",
       "       1\n",
       "      </td>\n",
       "     </tr>\n",
       "    </tbody>\n",
       "   </table>\n",
       "  </table>\n",
       " </body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table><thead><tr><td></td><td><b>Mediatronic,</b></td><td><b>Medtronic,</b></td><td><b>Medtronic,</b></td><td><b>Semiary</b></td><td><b>Consoliddating</b></td><td><b>Consolidating</b></td><td><b>Total</b></td></tr></thead><tbody><tr><td>Costs sold</td><td>1</td><td>1,261</td><td>5</td><td>0,659</td><td>1,245</td><td>1,245</td><td>1,360</td></tr><tr><td>Research and development expenses</td><td>1</td><td>1</td><td>552</td><td>1,586</td><td>1,044</td><td>1,645</td><td>1,900</td></tr><tr><td>Acquisition-related items</td><td>Other expense (income), net</td><td>1034</td><td>145</td><td>(56)</td><td>3,734</td><td>(16)</td><td>7,726</td></tr><tr><td>Indirected inactivity</td><td>1</td><td>1</'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp_006",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
